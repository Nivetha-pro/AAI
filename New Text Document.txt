import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.gaussian_process import GaussianProcessClassifier
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C
from sklearn.metrics import accuracy_score, classification_report

# Load the dataset
file_path = r'C:\Users\Student\Documents\Module Dev Containers\AAI-assignment\AAI-assignement-main\AAI-assignement-main\Datasets and old trials\parkinsons_data-VOICE-features.csv'
data = pd.read_csv(file_path)

# Drop unnecessary columns
data = data.drop(columns=['name'])

# Define features and target variable
X = data.drop(columns=['status'])
y = data['status']

# Split the dataset into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Standardize the features
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Define Gaussian Process kernel
# Use a constant kernel multiplied by an RBF kernel (typical choice for GPs)
kernel = C(1.0, (1e-3, 1e3)) * RBF(1, (1e-2, 1e2))

# Initialize and fit Gaussian Process Classifier
gpc = GaussianProcessClassifier(kernel=kernel, random_state=42)
gpc.fit(X_train, y_train)

# Make predictions on the test set
y_pred = gpc.predict(X_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

print(f"Accuracy: {accuracy:.2f}")
print("Classification Report:")
print(report)

# Step 1: Define the input values for the query
query_data = {
    'MDVP:Fo(Hz)': 197.076,
    'MDVP:Fhi(Hz)': 206.896,
    'MDVP:Flo(Hz)': 192.055,
    'MDVP:Jitter(%)': 0.00289,
    'MDVP:Jitter(Abs)': 0.00001,
    'MDVP:RAP': 0.00166,
    'MDVP:PPQ': 0.00168,
    'Jitter:DDP': 0.00498,
    'MDVP:Shimmer': 0.01098,
    'MDVP:Shimmer(dB)': 0.097,
    'Shimmer:APQ3': 0.00563,
    'Shimmer:APQ5': 0.0068,
    'MDVP:APQ': 0.00802,
    'Shimmer:DDA': 0.01689,
    'NHR': 0.00339,
    'HNR': 26.775
}

# Step 2: Add missing features with placeholder values (e.g., 0 or NaN)
all_features = X.columns.tolist()  # Get the list of all feature names from training data
missing_features = set(all_features) - set(query_data.keys())

# Add the missing features to the query data with default values (e.g., 0)
for feature in missing_features:
    query_data[feature] = 0  # Placeholder value (or use np.nan if you prefer)

# Step 3: Convert the dictionary to a DataFrame and ensure it matches the feature columns in order
query_df = pd.DataFrame([query_data])

# Step 4: Ensure the query DataFrame columns match the order in the training data
query_df = query_df[all_features]

# Step 5: Apply the same scaling transformation
query_scaled = scaler.transform(query_df)

# Step 6: Predict probability for status = 0 (no Parkinson's)
probabilities = gpc.predict_proba(query_scaled)
prob_status_0 = probabilities[0][0]  # Probability of status = 0 (no Parkinson's)

# Output the result
print("P(status=0 | given features) =", prob_status_0)
