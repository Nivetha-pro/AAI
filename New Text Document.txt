 K-Fold Cross-Validation for 2 datastes


from sklearn.model_selection import KFold, cross_val_score
from sklearn.ensemble import RandomForestClassifier  # or any model of your choice
from sklearn.metrics import accuracy_score
import pandas as pd

# Load your datasets
# Assuming they are CSV files, you can replace 'dataset1.csv' and 'dataset2.csv' with the actual file names.
dataset1 = pd.read_csv('path_to_dataset1.csv')
dataset2 = pd.read_csv('path_to_dataset2.csv')

# Define the features (X) and labels (y) for both datasets
# Replace 'target' with the actual target column name
X1, y1 = dataset1.drop(columns=['target']), dataset1['target']
X2, y2 = dataset2.drop(columns=['target']), dataset2['target']

# Set up cross-validation parameters
kf = KFold(n_splits=5, shuffle=True, random_state=42)
model = RandomForestClassifier()  # Use any classifier of choice

# Function to evaluate using cross-validation
def evaluate_model(X, y):
    scores = []
    for train_index, test_index in kf.split(X):
        X_train, X_test = X.iloc[train_index], X.iloc[test_index]
        y_train, y_test = y.iloc[train_index], y.iloc[test_index]
        
        # Train the model
        model.fit(X_train, y_train)
        
        # Predict and evaluate
        y_pred = model.predict(X_test)
        score = accuracy_score(y_test, y_pred)
        scores.append(score)
    
    print(f'Average Accuracy: {sum(scores) / len(scores):.2f}')
    return scores

# Evaluate for each dataset
print("Dataset 1:")
scores1 = evaluate_model(X1, y1)

print("\nDataset 2:")
scores2 = evaluate_model(X2, y2)
